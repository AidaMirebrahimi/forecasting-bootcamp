{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df61c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277276c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import AutoFormer\n",
    "from datasets import ExchangeDataset\n",
    "from utils.data import split_data, get_day_features\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate\n",
    "from utils.metrics import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74216dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Constants\n",
    "CSV_PATH = \"data/exchange_rate/exchange_rate.csv\"\n",
    "TARGET_COLUMN = \"OT\"\n",
    "DATE_COLUMN = \"date\"\n",
    "\n",
    "TRAIN_PERC = .7\n",
    "TEST_PERC = .1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "SEQ_LEN = 96 #Input Sequence Length\n",
    "START_TOKEN_LEN = 48 #Start Token Length\n",
    "PRED_LEN = 96 #Prediction sequence length\n",
    "FEATURES = \"M\"\n",
    "OUTPUT_ATTENTION = False\n",
    "\n",
    "EPOCHS = 50\n",
    "LR = .0001\n",
    "LRADJ = \"type1\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65945d",
   "metadata": {},
   "source": [
    " ## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354d4897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990/1/1 0:00</td>\n",
       "      <td>0.785500</td>\n",
       "      <td>1.611000</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>0.634196</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.525486</td>\n",
       "      <td>0.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990/1/2 0:00</td>\n",
       "      <td>0.781800</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>0.861104</td>\n",
       "      <td>0.633513</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>0.523972</td>\n",
       "      <td>0.594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990/1/3 0:00</td>\n",
       "      <td>0.786700</td>\n",
       "      <td>1.629300</td>\n",
       "      <td>0.861030</td>\n",
       "      <td>0.648508</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.597300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990/1/4 0:00</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>1.637000</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.650618</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>0.523834</td>\n",
       "      <td>0.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990/1/5 0:00</td>\n",
       "      <td>0.784900</td>\n",
       "      <td>1.653000</td>\n",
       "      <td>0.861995</td>\n",
       "      <td>0.656254</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.527426</td>\n",
       "      <td>0.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>2010/10/6 0:00</td>\n",
       "      <td>0.718494</td>\n",
       "      <td>1.222195</td>\n",
       "      <td>0.737485</td>\n",
       "      <td>0.969974</td>\n",
       "      <td>0.143697</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.688565</td>\n",
       "      <td>0.690846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>2010/10/7 0:00</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>1.223459</td>\n",
       "      <td>0.741155</td>\n",
       "      <td>0.977297</td>\n",
       "      <td>0.143763</td>\n",
       "      <td>0.008595</td>\n",
       "      <td>0.690288</td>\n",
       "      <td>0.695701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>2010/10/8 0:00</td>\n",
       "      <td>0.723197</td>\n",
       "      <td>1.234111</td>\n",
       "      <td>0.745184</td>\n",
       "      <td>0.984446</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.691419</td>\n",
       "      <td>0.695943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>2010/10/9 0:00</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>1.233905</td>\n",
       "      <td>0.744131</td>\n",
       "      <td>0.980344</td>\n",
       "      <td>0.143993</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.690942</td>\n",
       "      <td>0.692689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>2010/10/10 0:00</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>1.233905</td>\n",
       "      <td>0.744131</td>\n",
       "      <td>0.980344</td>\n",
       "      <td>0.143993</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.690942</td>\n",
       "      <td>0.692689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7588 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date         0         1         2         3         4  \\\n",
       "0       1990/1/1 0:00  0.785500  1.611000  0.861698  0.634196  0.211242   \n",
       "1       1990/1/2 0:00  0.781800  1.610000  0.861104  0.633513  0.211242   \n",
       "2       1990/1/3 0:00  0.786700  1.629300  0.861030  0.648508  0.211242   \n",
       "3       1990/1/4 0:00  0.786000  1.637000  0.862069  0.650618  0.211242   \n",
       "4       1990/1/5 0:00  0.784900  1.653000  0.861995  0.656254  0.211242   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "7583   2010/10/6 0:00  0.718494  1.222195  0.737485  0.969974  0.143697   \n",
       "7584   2010/10/7 0:00  0.721839  1.223459  0.741155  0.977297  0.143763   \n",
       "7585   2010/10/8 0:00  0.723197  1.234111  0.745184  0.984446  0.143997   \n",
       "7586   2010/10/9 0:00  0.720825  1.233905  0.744131  0.980344  0.143993   \n",
       "7587  2010/10/10 0:00  0.720825  1.233905  0.744131  0.980344  0.143993   \n",
       "\n",
       "             5         6        OT  \n",
       "0     0.006838  0.525486  0.593000  \n",
       "1     0.006863  0.523972  0.594000  \n",
       "2     0.006975  0.526316  0.597300  \n",
       "3     0.006953  0.523834  0.597000  \n",
       "4     0.006940  0.527426  0.598500  \n",
       "...        ...       ...       ...  \n",
       "7583  0.008500  0.688565  0.690846  \n",
       "7584  0.008595  0.690288  0.695701  \n",
       "7585  0.008562  0.691419  0.695943  \n",
       "7586  0.008555  0.690942  0.692689  \n",
       "7587  0.008555  0.690942  0.692689  \n",
       "\n",
       "[7588 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8dcbfc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Carve out date index and features\n",
    "dates = pd.to_datetime(df.iloc[:, 0])\n",
    "data = df.iloc[:, 1:]\n",
    "\n",
    "(train_data, train_dates), (val_data, val_dates), (test_data, test_dates) = split_data(data, dates, TRAIN_PERC, TEST_PERC)\n",
    "\n",
    "train_time_feat = get_day_features(train_dates)\n",
    "val_time_feat = get_day_features(val_dates)\n",
    "test_time_feat = get_day_features(test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490126d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (5311, 8) (5311, 3)\n",
      "validation (1519, 8) (1519, 3)\n",
      "test (758, 8) (758, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"train\", train_data.shape, train_time_feat.shape)\n",
    "train_dataset = ExchangeDataset(data=train_data,\n",
    "                                   time_feat=train_time_feat,\n",
    "                                   seq_len=SEQ_LEN,\n",
    "                                   start_token_len=START_TOKEN_LEN,\n",
    "                                   pred_len=PRED_LEN\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "print(\"validation\", val_data.shape, val_time_feat.shape)\n",
    "val_dataset = ExchangeDataset(data=val_data,\n",
    "                                   time_feat=val_time_feat,\n",
    "                                   seq_len=SEQ_LEN,\n",
    "                                   start_token_len=START_TOKEN_LEN,\n",
    "                                   pred_len=PRED_LEN\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
    "print(\"test\", test_data.shape, test_time_feat.shape)\n",
    "\n",
    "test_dataset = ExchangeDataset(data=test_data,\n",
    "                                   time_feat=test_time_feat,\n",
    "                                   seq_len=SEQ_LEN,\n",
    "                                   start_token_len=START_TOKEN_LEN,\n",
    "                                   pred_len=PRED_LEN\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e57a5",
   "metadata": {},
   "source": [
    " ## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ec7c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoFormer(\n",
       "  (decomp): SeriesDecomp(\n",
       "    (moving_avg): MovingAvg(\n",
       "      (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "    )\n",
       "  )\n",
       "  (enc_embedding): DataEmbedding_wo_pos(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(8, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=3, out_features=512, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): DataEmbedding_wo_pos(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(8, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=3, out_features=512, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (norm_layer): LayerNorm(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (attn_layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): AutoCorrelationLayer(\n",
       "          (inner_correlation): AutoCorrelation(\n",
       "            (dropout): Dropout(p=False, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (decomp1): SeriesDecomp(\n",
       "          (moving_avg): MovingAvg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (decomp2): SeriesDecomp(\n",
       "          (moving_avg): MovingAvg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (attention): AutoCorrelationLayer(\n",
       "          (inner_correlation): AutoCorrelation(\n",
       "            (dropout): Dropout(p=False, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (decomp1): SeriesDecomp(\n",
       "          (moving_avg): MovingAvg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (decomp2): SeriesDecomp(\n",
       "          (moving_avg): MovingAvg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (norm_layer): LayerNorm(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (projection): Linear(in_features=512, out_features=8, bias=True)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): AutoCorrelationLayer(\n",
       "          (inner_correlation): AutoCorrelation(\n",
       "            (dropout): Dropout(p=False, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attention): AutoCorrelationLayer(\n",
       "          (inner_correlation): AutoCorrelation(\n",
       "            (dropout): Dropout(p=False, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (decomp1): SeriesDecomp(\n",
       "          (moving_avg): MovingAvg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (decomp2): SeriesDecomp(\n",
       "          (moving_avg): MovingAvg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (decomp3): SeriesDecomp(\n",
       "          (moving_avg): MovingAvg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.05, inplace=False)\n",
       "        (projection): Conv1d(512, 8, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af_model = AutoFormer()\n",
    "opt = torch.optim.Adam(af_model.parameters(), lr=.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "af_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "supposed-tissue",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_step(af_model, train_loader, model_optim, criterion, device):\n",
    "    train_loss_list = []\n",
    "\n",
    "    af_model.train()\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "        batch_x = batch_x.float().to(device)\n",
    "\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        batch_x_mark = batch_x_mark.float().to(device)\n",
    "        batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -PRED_LEN:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :START_TOKEN_LEN, :], dec_inp], dim=1).float().to(device)\n",
    "\n",
    "        outputs = af_model(batch_x, batch_x_mark, dec_inp, batch_y_mark, batch_y)\n",
    "\n",
    "        f_dim = -1 if FEATURES == 'MS' else 0\n",
    "        batch_y = batch_y[:, -PRED_LEN:, f_dim:].to(device)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        train_loss = np.average(loss.detach().cpu().numpy())\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "    avg_train_loss = np.mean(train_loss_list)\n",
    "\n",
    "    return avg_train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expired-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(af_model, val_loader, criterion, device):\n",
    "    val_loss_list = []\n",
    "    af_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(val_loader):\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float()\n",
    "\n",
    "            batch_x_mark = batch_x_mark.float().to(device)\n",
    "            batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "            # decoder input\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -PRED_LEN:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :START_TOKEN_LEN, :], dec_inp], dim=1).float().to(device)\n",
    "            # encoder - decoder\n",
    "\n",
    "            outputs = af_model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            f_dim = -1 if FEATURES == 'MS' else 0\n",
    "            batch_y = batch_y[:, -PRED_LEN:, f_dim:].to(device)\n",
    "\n",
    "            pred = outputs.detach().cpu()\n",
    "            true = batch_y.detach().cpu()\n",
    "\n",
    "            loss = criterion(pred, true)\n",
    "\n",
    "            val_loss_list.append(loss)\n",
    "            \n",
    "    avg_val_loss = np.average(val_loss_list)\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mathematical-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(af_model, test_loader, run_name, device):\n",
    "    af_model.load_state_dict(torch.load(os.path.join('./checkpoints/' + run_name, 'checkpoint.pth')))\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    inputs = []\n",
    "    folder_path = './test_results/' + run_name + '/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    af_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "\n",
    "            batch_x_mark = batch_x_mark.float().to(device)\n",
    "            batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "            # decoder input\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -PRED_LEN:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :START_TOKEN_LEN, :], dec_inp], dim=1).float().to(device)\n",
    "            # encoder - decoder\n",
    "            outputs = af_model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            f_dim = -1 if FEATURES == 'MS' else 0\n",
    "            batch_y = batch_y[:, -PRED_LEN:, f_dim:].to(device)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "            inp = batch_x.detach().cpu().numpy()\n",
    "\n",
    "            pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
    "            true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
    "            \n",
    "\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "            inputs.append(inp)\n",
    "            \n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)\n",
    "    inputs = np.array(inputs)\n",
    "\n",
    "    print('test shape:', preds.shape, trues.shape)\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "    trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "    inputs = inputs.reshape(-1, inputs.shape[-2], inputs.shape[-1])\n",
    "    print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "    # result save\n",
    "    folder_path = './results/' + run_name + '/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "    print('mse:{}, mae:{}'.format(mse, mae))\n",
    "    f = open(\"result.txt\", 'a')\n",
    "    f.write(run_name + \"  \\n\")\n",
    "    f.write('mse:{}, mae:{}'.format(mse, mae))\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "    np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "    np.save(folder_path + 'pred.npy', preds)\n",
    "    np.save(folder_path + 'true.npy', trues)\n",
    "    np.save(folder_path + 'inputs.npy', inputs)\n",
    "\n",
    "    return inputs, preds, trues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732b77f",
   "metadata": {},
   "source": [
    "## Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tropical-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.592394).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "0 0.24791961156297476 0.59239393\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "1 0.23211329279001802 0.60624\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "2 0.2177584920078516 0.59982926\n",
      "Validation loss decreased (0.592394 --> 0.587200).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "3 0.20463224397972227 0.5872003\n",
      "Validation loss decreased (0.587200 --> 0.584572).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "4 0.19805167024023831 0.5845724\n",
      "Validation loss decreased (0.584572 --> 0.582613).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "5 0.1952524055726826 0.5826131\n",
      "Validation loss decreased (0.582613 --> 0.582365).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "6 0.1934375849785283 0.582365\n",
      "Validation loss decreased (0.582365 --> 0.582054).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "7 0.19217760302126408 0.58205384\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "8 0.1914797281846404 0.58243644\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "9 0.1920086262980476 0.58246285\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "#Train Step\n",
    "run_name = f\"run_{str(datetime.now().strftime('%s'))}\"\n",
    "\n",
    "path = os.path.join(\"./checkpoints/\", run_name)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "train_steps = len(train_loader)\n",
    "early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "model_optim = optim.Adam(af_model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_step(af_model, train_loader, model_optim, criterion, DEVICE)\n",
    "    val_loss = val_step(af_model, val_loader, criterion, DEVICE)\n",
    "\n",
    "    early_stopping(val_loss, af_model, path)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping\")\n",
    "        break\n",
    "    \n",
    "    adjust_learning_rate(model_optim, epoch+1, adjust_type=\"type1\", lr=LR)\n",
    "    \n",
    "    print(epoch, train_loss, val_loss)\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "binding-humor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe7d18bf820>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1, 2)\n",
    "\n",
    "x_index = [i for i in range(len(train_loss_list))]\n",
    "\n",
    "axarr[0].plot(x_index, train_loss_list)\n",
    "axarr[1].plot(x_index, val_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-harris",
   "metadata": {},
   "source": [
    "## Test and visualize predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "renewable-necklace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (17, 32, 96, 8) (17, 32, 96, 8)\n",
      "test shape: (544, 96, 8) (544, 96, 8)\n",
      "mse:0.7448254823684692, mae:0.6705881953239441\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28minput\u001b[39m, pred, true \u001b[38;5;241m=\u001b[39m test(af_model, test_loader, run_name, DEVICE)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minputs\u001b[49m\u001b[38;5;241m.\u001b[39mshape, preds\u001b[38;5;241m.\u001b[39mshape, trues\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "input, pred, true = test(af_model, test_loader, run_name, DEVICE)\n",
    "print(inputs.shape, preds.shape, trues.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_indices = np.random.choice(range(pred.shape[0]), 2, replace=False)\n",
    "ss_pred = pred[ss_indices]\n",
    "ss_true = true[ss_indices]\n",
    "ss_input = input[ss_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(pred.shape[2], ss_pred.shape[0], figsize=(40, 200))\n",
    "for i in range(ss_pred.shape[2]):\n",
    "    series_preds = ss_pred[:, :, i].squeeze()\n",
    "    series_trues = ss_true[:, :, i].squeeze()\n",
    "    series_inputs = ss_input[:, :, i].squeeze()\n",
    "    for j in range(ss_pred.shape[0]):\n",
    "        series_pred = series_preds[j, :].squeeze()\n",
    "        series_true = series_trues[j, :].squeeze()\n",
    "        series_input = series_inputs[j, :].squeeze()\n",
    "        input_len = series_input.shape[0]\n",
    "        pred_gt_len = series_pred.shape[0]\n",
    "\n",
    "        input_x = np.array([i for i in range(input_len)])\n",
    "        x = np.array([i for i in range(input_len, input_len+pred_gt_len)])\n",
    "        axarr[i, j].plot(x, series_pred, c=\"blue\", label=\"predictions\")\n",
    "        axarr[i, j].plot(x, series_true, c=\"red\", label=\"ground truth\")\n",
    "        axarr[i, j].plot(input_x, series_input, c=\"green\", label=\"input\")\n",
    "        axarr[i, j].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-design",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoformer",
   "language": "python",
   "name": "autoformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
